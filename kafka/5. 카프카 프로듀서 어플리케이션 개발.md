# 카프카 프로슈더 어플리케이션 개발

### 프로듀서

- 카프카에서 데이터의 시작점은 프로듀서이다.
- 프로듀서는 리더 파티션을 가지고 있는 카프카 브로커와 통신한다.
- 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

***
### 프로듀서 내부 구조

![프로듀서 내부구조.png](img/section5/프로듀서%20내부구조.png)

- ProducerRecord : 프로듀서에서 생성하는 레코드, 오프셋은 미포함
- send() : 레코드 전송 메서드
- Partitioner : 어느 파티션으로 전송할 지 지정하는 파티셔너, 기본값으로 DefaultPartitioner로 설정
- Accumulator : 배치로 묶어서 전송할 데이터를 모으는 버퍼

***
### 프로듀서 기본 파티셔너
- 카프카 2.5.0 이전 : RoundRobinPartitioner
- 카프카 2.5.0 이후 : UniformStickyPartitioner


- 메세지 키가 있을 경우
  - 메세지 키의 해시 값과 파티션을 매칭하여 전송
  - 동일한 메세지 키가 존재하는 레코드는 동일한 파티션 번호로 전달
  - 만약 파티션의 개수가 증가 될 경우 메세지 키 해시 값이 초기화 되어서 파티션 번호 매칭이 초기화 된다.


- 메세지 키가 없을 경우
  - RoundRobinPartitioner
    - 파티션을 순회하며 전송
    - Accumulator 에서 묶이는 정도가 적음, 전송 성능이 낮음
  - UniformStickyPartitioner
    - Accumulator 에서 배치로 묶일 때까지 기다렸다가 전송, 성능 우수
    - 파티션을 순회하면서 전송하는 방식은 동일

***
### 프로듀서 커스텀 파티셔너
- Partitioner 인터페이스를 사용자 클래스에서 구현
- 메세지 키 또는 메세지 값에 따른 파티션 지정 로직 적용 가능

***
### 프로듀서 주요 옵션(필수)
- bootstrap.servers : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트 를 1개 이상 작성
- key.serializer : 레코드의 메세지 키를 직렬화 하는 클래스 지정
- value.serializer : 레코드의 메세지 값을 직렬화 하는 클래스 지정
- Serializer 클래스는 StringSerializer 클래스로 보통 지정한다.
  - StringSerializer 클래스가 디스크 크기를 많이 잡아먹는 단점이 있으나 kafka-console-consumer.sh 에서 디버깅이 가능하며 Consumer 에서도 역직렬화 방식을 맞춰야 하기 때문에 유지보수 편의성을 위해 별다른 이슈가 없는 한 StringSerializer 로 통일한다.

***
### 프로듀서 주요 옵션(선택)
- acks : 프로듀서가 전송한 데이터가 브로커들에 정상적으로 전송 되었는지 확인 여부 옵션
  - 0 : 확인 안함
  - 1 : 리더 파티션 까지 확인. **default 값**
  - -1(all) : 리더 파티션 > 팔로워 파티션 복제 까지 확인
    - min.insync.replicas 설정 수 만큼 팔로워 파티션의 복제 개수를 확인(리더 파티션 포함)

- linger.ms : 배치를 전송하기 전까지 기다리는 최소 시간. **기본값은 0**
  - 별도 설정 없으면 배치 없이 실시간 전송(다량의 요청이 들어오면 네트워크 부담으로 인한 성능저하가 있을 수 있음)
- retries : 브로커로부터 에러를 받고 난 뒤 재전송 시도 횟수. **기본값은 Interger.MAX_VALUE**
- max.in.flight.request.per.connection : 한번에 요청하는 최대 커넥션 개수. 설정된 값 만큼 동시 전달 요청. **기본값은 5**
- partitioner.class : 레코드를 파티션에 전송할 때 적용되는 파티셔너 클래스 지정. **기본 값은 DefaultPartitioner**
- enable.idempotence : 멱등성 프로듀서 동작 여부 설정. **기본 값은 3.0 이후 true**
- transactional.id : 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을지 여부를 설정. **기본 값은 null**

***
### acks

- acks 옵션에 따라서 신뢰성, 성능에 영향을 미침
- 복제 개수(replication-factor)가 2개 이상일 경우 acks 옵션에 따른 영향도
  - 0 : 리더 파티션에 데이터가 저장 되었는지 여부 자체를 확인하지 않기 때문에 신뢰도는 낮으나, 성능은 높음
  - **1(default)** : 리더 파티션에 데이터가 저장 되었는지 확인, 팔로워 파티션 저장 여부는 확인하지 않으므로 데이터 유실 가능성이 존재
  - -1(all) : 리더 파티션 > 팔로워 파티션 복제 여부 까지 확인, 신뢰도 높으나, 성능은 낮음
    - min.insync.replicas 설정 수 만큼 팔로워 파티션의 복제 개수를 확인(리더 파티션 포함)
    - 신뢰도를 높이는 설정
      - acks = ALL / replication-factor = 3 / min.insync.replicas = 2
      - replication-factor == min.insync.replicas 으면 팔로워 파티션의 브로커에 장애가 있을 경우에도 데이터를 송/수신 받지 못하는 상황이 발생할 수 있으므로 min.insync.replicas 는 replication-factor 개수 보다 1~2개 작게 설정  

***
### 커스텀 파티셔너 설정 프로듀서

**- CustomPartitioner**
- 메세지 key가 "Pangyo" 이면 0번 파티션으로 저장
- 그 외에는 DefaultPartitioner 처럼 메세지 key 해싱 값으로 partition 번호 매칭
```java
public class CustomPartitioner  implements Partitioner {

    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes,
                         Cluster cluster) {

        if (keyBytes == null) {
            throw new InvalidRecordException("Need message key");
        }
        if (((String)key).equals("Pangyo"))
            return 0;

        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        int numPartitions = partitions.size();
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
```

**- DefaultPartitioner**
- 메세지 key가 없으면 UniformStickyPartitioner 처럼 동작
- 메세지 key가 있으면 Hashing 되어 있는 파티션 번호 매칭
```java
public class DefaultPartitioner implements Partitioner {
  //...(중략)
  public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    if (keyBytes == null) {
      return stickyPartitionCache.partition(topic, cluster);
    }
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    // hash the keyBytes to choose a partition
    return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
  }
}
```

***
### 레코드 전송 결과를 확인하는 프로듀서(Sync)

```java
/**
 * Sync 방식으로 응답을 받는다 
 */
public class ProducerWithSyncCallback {
    private final static Logger logger = LoggerFactory.getLogger(ProducerWithSyncCallback.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {

        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        //configs.put(ProducerConfig.ACKS_CONFIG, "0");   // acks를 0으로 설정하면 파티션 정상 저장 여부를 검증하지 않고 응답하므로 오프셋이 -1로 출력된다.

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "Pangyo", "Pangyo");
        try {
            RecordMetadata metadata = producer.send(record).get();
            logger.info(metadata.toString());
        } catch (Exception e) {
            logger.error(e.getMessage(),e);
        } finally {
            producer.flush();
            producer.close();
        }
    }
}
```

- acks = 1(default) 일 때, test 토픽에 0번 파티션에 8번 offset에 정상 저장되었음을 의미
  ```shell
  [kafka-producer-network-thread | producer-1] INFO com.example.ProducerCallback - test-0@8
  ```
  
- acks = 0 일 때, test 토픽에 0번 파티션에 정상응답을 받지 않았으므로 offset이 -1 로 출력
  ```shell
  [main] INFO com.example.ProducerWithSyncCallback - test-0@-1
  ```

***
### 레코드 전송 결과를 확인하는 프로듀서(Async)

```java
/**
 * Async 방식으로 응답을 받는다 
 */
public class ProducerWithAsyncCallback {
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {

        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "Pangyo", "Pangyo");
        producer.send(record, new ProducerCallback());

        producer.flush();
        producer.close();
    }
}

/**
 * Callback 인터페이스 구현
 */
public class ProducerCallback implements Callback {
  private final static Logger logger = LoggerFactory.getLogger(ProducerCallback.class);

  @Override
  public void onCompletion(RecordMetadata recordMetadata, Exception e) {
    if (e != null)
      logger.error(e.getMessage(), e);
    else
      logger.info(recordMetadata.toString());
  }
}
```

***
### 프로듀서의 안전한 종료

- 프로듀서를 안전하게 종료하기 위해서는 flush, close 메서드를 사용해서 Accumulator 에 저장되어 있는 데이터를 카프카 클러스터로 전송야한다.
```
producer.flush(); // Accumulator > Sender 로 전송
producer.close(); // Accumulator 정상 종료
```
